{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "religious-romantic",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Thinking of making batch size large and just use the batch as the set of images to cluster\n",
    "- If want to go for variable dataset sizes, can just have an outer loop that will change the batch size but train the same model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-roommate",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standing-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from permnet import PermNet\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import *\n",
    "from pyro.infer import Predictive, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, AdamW\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-proof",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "united-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
    "\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((.5), (.5))\n",
    "        ])\n",
    "    out_dir = './data/mnist'\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "\n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "N = 100\n",
    "data = mnist_data()\n",
    "# Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=N, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-guarantee",
   "metadata": {},
   "source": [
    "### Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continent-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, step):\n",
    "    # global variables\n",
    "    alpha = torch.ones(T)\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))\n",
    "    \n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(torch.zeros(M), torch.eye(M)))\n",
    "\n",
    "    # use PCA to reduce dimensionality so I can train faster\n",
    "    img_set = images_to_vectors(data.squeeze())\n",
    "    (U, S, V) = torch.pca_lowrank(img_set, q=None, center=True, niter=10)\n",
    "    z = torch.matmul(data, V[:, :100000])\n",
    "    # local variables\n",
    "    with pyro.plate('data', N):\n",
    "        assignment = pyro.sample('assignments', Categorical(weights))\n",
    "        pyro.sample('obs', MultivariateNormal(locs[assignment], torch.eye(M)), obs=z)\n",
    "        \n",
    "def guide(data, step):\n",
    "    # amortize using MLP\n",
    "    \n",
    "    if use_gpu: \n",
    "        data = data.cuda()\n",
    "        \n",
    "    tau = tau_mlp(data.float())\n",
    "    tau = tau.view(T,M)\n",
    "\n",
    "    # sample mixture components mu\n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(tau, torch.eye(M)))\n",
    "    \n",
    "    # sample cluster assignments\n",
    "    alpha = alpha_mlp(data.float()) # returns a vector of length T\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))  # vector of length T\n",
    "    with pyro.plate('data', size=N):\n",
    "        assignments = pyro.sample('assignments', Categorical(weights))\n",
    "    \n",
    "    # logging\n",
    "    if step % 2 == 0:\n",
    "        \n",
    "        print('='*10, 'Iteration {}'.format(step), '='*10)\n",
    "        weight_data = [weights[0][i] for i in range(len(weights[0]))]\n",
    "        weight_data.insert(0, 'props')\n",
    "\n",
    "        mu1_data = [locs[i,0] for i in range(locs.shape[0])]\n",
    "        mu1_data.insert(0, 'mu1')\n",
    "\n",
    "        mu2_data = [locs[i,1] for i in range(locs.shape[0])]\n",
    "        mu2_data.insert(0, 'mu2')\n",
    "        \n",
    "        mu3_data = [locs[i,2] for i in range(locs.shape[0])]\n",
    "        mu3_data.insert(0, 'mu3')\n",
    "        \n",
    "        mu4_data = [locs[i,3] for i in range(locs.shape[0])]\n",
    "        mu4_data.insert(0, 'mu4')\n",
    "        \n",
    "        mu5_data = [locs[i,4] for i in range(locs.shape[0])]\n",
    "        mu5_data.insert(0, 'mu5')\n",
    "        \n",
    "        mu6_data = [locs[i,5] for i in range(locs.shape[0])]\n",
    "        mu6_data.insert(0, 'mu6')\n",
    "        \n",
    "        \n",
    "        data = [weight_data, mu1_data, mu2_data, mu3_data, mu4_data, mu5_data, mu6_data]\n",
    "        \n",
    "        print(tabulate(data, headers=['', 'clust1', 'clust2', 'clust3', 'clust4', 'clust5', 'clust6', 'clust7', 'clust8', 'clust9', 'clust10']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-reason",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empty-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using GPU!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyang/.local/lib/python3.7/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "M = 6  # how many features after pca\n",
    "alpha_mlp = PermNet(num_pixels=784, hidden=2048, output_size=T).float()\n",
    "tau_mlp = PermNet(num_pixels=784, hidden=2048, output_size=T*M).float()\n",
    "\n",
    "adam_params = {\"lr\": 0.00001}\n",
    "optimizer = Adam(adam_params)\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('using GPU!')\n",
    "    alpha_mlp = alpha_mlp.cuda()\n",
    "    tau_mlp = tau_mlp.cuda()\n",
    "else:\n",
    "    print('not using GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-cloud",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Iteration 0 ==========\n",
      "         clust1     clust2      clust3     clust4     clust5     clust6    clust7      clust8    clust9    clust10\n",
      "-----  --------  ---------  ----------  ---------  ---------  ---------  --------  ----------  --------  ---------\n",
      "props  0.220254  0.0136781   0.0502475  0.106647   0.0562601  0.0284842  0.097218   0.0823469  0.143951   0.200912\n",
      "mu1    0.537987  2.33507    -0.957864   0.449947   2.93169    2.5207     3.07959    3.17407    1.64365    1.46379\n",
      "mu2    1.56636   2.94652     2.27128    0.0901594  1.47747    2.54397    2.84904    0.109354   3.51041    3.04167\n",
      "mu3    3.06897   2.35485     3.35059    3.44511    2.69556    0.902499   2.7231     1.72833    1.97658    2.06199\n",
      "mu4    1.44914   1.57254     0.113334   3.76592    3.21001    3.61562    1.19541    3.7302     2.21537    2.67731\n",
      "mu5    0.258158  0.421295    1.94493    1.43892    0.552475   1.53576    1.47021    1.27526    1.6497     1.58753\n",
      "mu6    1.19847   2.13961     1.50532    2.56593    4.06919    2.69376    0.922602  -0.335689   4.14129    1.03504\n",
      "took 12.623230457305908 seconds\n",
      "========== Iteration 2 ==========\n",
      "          clust1    clust2      clust3     clust4    clust5     clust6    clust7    clust8     clust9    clust10\n",
      "-----  ---------  --------  ----------  ---------  --------  ---------  --------  --------  ---------  ---------\n",
      "props  0.0528231  0.267067   0.0642418  0.0254852  0.024659  0.071775   0.186708  0.147896  0.0384363   0.120909\n",
      "mu1    5.65998    4.98445    3.21469    5.75521    1.43867   4.30672    1.71706   5.6445    6.93672     9.97991\n",
      "mu2    0.932987   3.22945    1.31459    3.56676    2.0439    3.25524    3.08015   2.81596   1.22395     1.55641\n",
      "mu3    4.40376    4.12062    0.883798   2.66439    3.34444   0.728359   3.69959   2.51896   1.11837     0.868441\n",
      "mu4    1.71817    0.544158  -1.18017    3.46425    1.32845   2.51021    2.69708   0.834989  1.49118     0.923833\n",
      "mu5    2.41617    2.38941    0.134147   0.107704   1.38489   0.0843154  3.00861   2.01404   2.45488     1.40947\n",
      "mu6    1.44935    1.12138    2.76117    1.22003    0.250059  1.69157    2.05673   1.86513   3.57412     3.2435\n",
      "took 27.781212329864502 seconds\n",
      "========== Iteration 4 ==========\n",
      "          clust1      clust2     clust3     clust4    clust5     clust6    clust7    clust8     clust9    clust10\n",
      "-----  ---------  ----------  ---------  ---------  --------  ---------  --------  --------  ---------  ---------\n",
      "props  0.0170482   0.0237622  0.0929737  0.136256   0.195209  0.0380971  0.126468  0.133415  0.0481052   0.188666\n",
      "mu1    5.8856      4.01455    3.66598    2.63       2.88656   3.75132    4.27005   4.02121   4.47449    11.7611\n",
      "mu2    0.973166    2.25414    1.06987    3.27325    1.52469   1.36189    3.25107   2.96444   2.552       0.647581\n",
      "mu3    1.9793      1.98036    0.816033   0.72838    1.99213   2.70744    2.13169   1.98816   2.0781      3.21809\n",
      "mu4    2.81797     2.54262    3.44872    0.745813   1.9341    3.06823    2.03376   0.097472  1.66019     1.55884\n",
      "mu5    1.57424    -0.337012   1.4642     1.01594    2.29679   4.33947    2.11687   2.09323   2.35301     2.23111\n",
      "mu6    3.4896      2.69458    1.92397    0.0571998  1.18356   1.27136    2.79372   2.80408   0.966632    2.41116\n",
      "took 26.77284288406372 seconds\n",
      "========== Iteration 6 ==========\n",
      "         clust1    clust2     clust3     clust4    clust5     clust6     clust7    clust8    clust9     clust10\n",
      "-----  --------  --------  ---------  ---------  --------  ---------  ---------  --------  --------  ----------\n",
      "props  0.128547  0.118488  0.0188804  0.0349785  0.255978   0.074068  0.0853984  0.144609  0.056791   0.0822611\n",
      "mu1    6.00258   5.20152   5.98345    5.39078    5.47398    4.75542   4.05422    4.20437   6.07394    8.57926\n",
      "mu2    0.839364  1.67052   3.18076    0.385907   0.255465  -0.239932  2.08131    1.83998   1.09699   -0.411413\n",
      "mu3    2.27643   1.88339   0.360224   2.85006    1.74986    1.96171   2.3927     1.03418   0.61561    2.6743\n",
      "mu4    1.35133   1.39999   1.97537    2.02263    0.35654   -0.703415  2.68644    1.77004   1.90566    3.24713\n",
      "mu5    0.216034  2.31878   1.71273    1.66193    3.53268    1.76804   2.84749    3.15212   2.84876    1.17407\n",
      "mu6    1.97951   1.14249   0.857031   0.555642   2.59185    1.41223   1.49166    2.59603   2.64231    1.93011\n",
      "took 26.648961067199707 seconds\n",
      "========== Iteration 8 ==========\n",
      "          clust1    clust2      clust3     clust4     clust5      clust6      clust7    clust8     clust9    clust10\n",
      "-----  ---------  --------  ----------  ---------  ---------  ----------  ----------  --------  ---------  ---------\n",
      "props   0.123133  0.189085   0.0862204  0.0903144  0.0637479   0.0763677   0.0932035  0.140314  0.0938436  0.0437711\n",
      "mu1     4.49665   6.62752    7.75765    6.11467    5.22817     4.7262      7.34013    6.15992   4.9514     5.49587\n",
      "mu2     1.68306   2.42553    1.09006    2.19689    1.71872     0.935743   -0.0266007  1.8924    2.45992    2.06752\n",
      "mu3    -1.36904   2.71082    1.08624    1.54014    1.62108    -0.443102    2.3782     0.52693   1.32573    2.74054\n",
      "mu4     0.681433  4.01253    0.271472   1.95203    0.442299    1.1102     -0.317653   2.29875   1.79557    1.58483\n",
      "mu5     0.737142  1.64232   -0.18701    0.89424    2.18069     1.28923     0.72529    1.25342   2.0206     3.29559\n",
      "mu6     1.43515   0.309144   1.08214    0.471489   1.6715      1.71007     1.75058    3.76793   1.11316    0.933703\n",
      "took 27.939888954162598 seconds\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "dry = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
    "        \n",
    "        data = images_to_vectors(real_batch).unsqueeze(0)\n",
    "        \n",
    "        n_steps = 10\n",
    "        start = time.time()\n",
    "        for step in range(n_steps):\n",
    "            svi.step(data, step)\n",
    "            pyro.get_param_store()\n",
    "            if step % 2 == 0:\n",
    "                end = time.time()\n",
    "                print('took', end-start, 'seconds')\n",
    "                start = time.time()\n",
    "\n",
    "        if not dry:\n",
    "            torch.save({'model_state_dict': alpha_mlp.state_dict(),\n",
    "                       }, 'saved_models/alpha_mlp_{}.pth'.format(step))\n",
    "\n",
    "            torch.save({'model_state_dict': tau_mlp.state_dict(),\n",
    "                       }, 'saved_models/tau_mlp_{}.pth'.format(step))\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc532w",
   "language": "python",
   "name": "cpsc532w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

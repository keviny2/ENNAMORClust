{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brazilian-power",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Ensemble voting method for cluster labels?\n",
    "\n",
    "## Bugs\n",
    "\n",
    "## Combinations\n",
    "- {lr: 0.0001, N: 200, niter: 20, n_iter: 300} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-viewer",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "undefined-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointnet import PointNet\n",
    "from permnet import PermNet\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import *\n",
    "from pyro.infer import Predictive, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, AdamW\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-ukraine",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prerequisite-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n",
    "\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((.5), (.5))\n",
    "        ])\n",
    "    out_dir = './data/mnist'\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "\n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "national-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "N = 100\n",
    "data = mnist_data()\n",
    "# Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=N, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-hudson",
   "metadata": {},
   "source": [
    "### Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "united-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, step, assignment_list):\n",
    "    # global variables\n",
    "    alpha = torch.ones(T)\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))\n",
    "    \n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(torch.zeros(M), torch.eye(M)))\n",
    "\n",
    "    # use PCA to reduce dimensionality so I can train faster\n",
    "    img_set = images_to_vectors(data.squeeze())\n",
    "    (U, S, V) = torch.pca_lowrank(img_set, q=None, center=True, niter=20)\n",
    "    z = torch.matmul(data, V[:, :100000])\n",
    "    # local variables\n",
    "    with pyro.plate('data', N):\n",
    "        assignment = pyro.sample('assignments', Categorical(weights))\n",
    "        pyro.sample('obs', MultivariateNormal(locs[assignment], torch.eye(M)), obs=z)\n",
    "        \n",
    "def guide(data, step, assignment_list):\n",
    "    # train nn if doing offline training\n",
    "    if not amortize:\n",
    "        pyro.module('alpha_mlp', alpha_mlp)\n",
    "        pyro.module('tau_mlp', tau_mlp)\n",
    "    \n",
    "    if use_gpu: \n",
    "        data = data.cuda()\n",
    "        \n",
    "    tau = tau_mlp(data.float())\n",
    "    tau = tau.view(T,M)\n",
    "\n",
    "    # sample mixture components mu\n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(tau, torch.eye(M)))\n",
    "    \n",
    "    # sample cluster assignments\n",
    "    alpha = alpha_mlp(data.float()) # returns a vector of length T\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))  # vector of length T\n",
    "    with pyro.plate('data', size=N):\n",
    "        assignments = pyro.sample('assignments', Categorical(weights))\n",
    "    \n",
    "    # logging\n",
    "    if step % log_iter == 0:\n",
    "        \n",
    "        print('='*10, 'Iteration {}'.format(step), '='*10)\n",
    "        assignment_list.append(assignments)\n",
    "        \n",
    "        weight_data = [weights.squeeze()[i] for i in range(len(weights.squeeze()))]\n",
    "        weight_data.insert(0, 'props')\n",
    "\n",
    "        pc1_data = [locs[i,0] for i in range(locs.shape[0])]\n",
    "        pc1_data.insert(0, 'pc1')\n",
    "\n",
    "        pc2_data = [locs[i,1] for i in range(locs.shape[0])]\n",
    "        pc2_data.insert(0, 'pc2')\n",
    "        \n",
    "        pc3_data = [locs[i,2] for i in range(locs.shape[0])]\n",
    "        pc3_data.insert(0, 'pc3')\n",
    "        \n",
    "        pc4_data = [locs[i,3] for i in range(locs.shape[0])]\n",
    "        pc4_data.insert(0, 'pc4')\n",
    "        \n",
    "        pc5_data = [locs[i,4] for i in range(locs.shape[0])]\n",
    "        pc5_data.insert(0, 'pc5')\n",
    "        \n",
    "        pc6_data = [locs[i,5] for i in range(locs.shape[0])]\n",
    "        pc6_data.insert(0, 'pc6')\n",
    "        \n",
    "        \n",
    "        data = [weight_data, pc1_data, pc2_data, pc3_data, pc4_data, pc5_data, pc6_data]\n",
    "        \n",
    "        print(tabulate(data, headers=['', 'clust1', 'clust2', 'clust3', 'clust4', 'clust5', 'clust6', 'clust7', 'clust8', 'clust9', 'clust10']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-integral",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "anonymous-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using GPU!\n"
     ]
    }
   ],
   "source": [
    "T = 10  # num components\n",
    "M = 6  # how many features after pca\n",
    "\n",
    "mlp_type = 'convnet'\n",
    "amortize = False\n",
    "\n",
    "if mlp_type == 'pointnet':\n",
    "    alpha_mlp = PointNet(in_ch=784, output_size=T).float() \n",
    "    tau_mlp = PointNet(in_ch=784, output_size=T*M, softmax=False).float()\n",
    "if mlp_type == 'permnet':\n",
    "    alpha_mlp = PermNet(in_ch=784, hidden=2048, output_size=T).float()\n",
    "    tau_mlp = PermNet(in_ch=784, hidden=2048, output_size=T*M).float()\n",
    "if mlp_type == 'convnet':\n",
    "    alpha_mlp = PermNet(in_ch=784, hidden=1024, output_size=T).float()\n",
    "    tau_mlp = PermNet(in_ch=784, hidden=1024, output_size=T*M).float()\n",
    "    \n",
    "    \n",
    "if amortize:\n",
    "    saved_alpha_mlp = torch.load('saved_models/{}/mnist_alpha_mlp.pth'.format(mlp_type))\n",
    "    saved_tau_mlp = torch.load('saved_models/{}/mnist_tau_mlp.pth'.format(mlp_type))\n",
    "    \n",
    "    alpha_mlp.load_state_dict(saved_alpha_mlp['model_state_dict'])\n",
    "    tau_mlp.load_state_dict(saved_tau_mlp['model_state_dict'])\n",
    "\n",
    "adam_params = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_params)\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('using GPU!')\n",
    "    alpha_mlp = alpha_mlp.cuda()\n",
    "    tau_mlp = tau_mlp.cuda()\n",
    "else:\n",
    "    print('not using GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-closer",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry = False\n",
    "log_iter = 100\n",
    "\n",
    "for n_batch, (real_batch, labels) in enumerate(data_loader):\n",
    "    data = images_to_vectors(real_batch).unsqueeze(0)\n",
    "    assignment_list = []\n",
    "    elbo_ests = []\n",
    "    n_steps = 500\n",
    "    start = time.time()\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        elbo_est = svi.step(data, step, assignment_list)\n",
    "        elbo_ests.append(elbo_est)\n",
    "        if step % log_iter == 0:\n",
    "            end = time.time()\n",
    "            print('took', end-start, 'seconds')\n",
    "            start = time.time()\n",
    "\n",
    "    if not dry:\n",
    "        torch.save({'model_state_dict': alpha_mlp.state_dict(),\n",
    "                    'assignments': assignment_list[-1],\n",
    "                    'elbo_ests': elbo_ests,\n",
    "                    'steps': n_steps,\n",
    "                    'images': data,\n",
    "                    'labels': labels\n",
    "                   }, 'saved_models/{0}/mnist_alpha_mlp_{1}.pth'.format(mlp_type, n_steps))\n",
    "\n",
    "        torch.save({'model_state_dict': tau_mlp.state_dict(),\n",
    "                    'assignments': assignment_list[-1],\n",
    "                    'elbo_ests': elbo_ests,\n",
    "                    'steps': n_steps,\n",
    "                    'images': data,\n",
    "                    'labels': labels\n",
    "                   }, 'saved_models/{0}/mnist_tau_mlp_{1}.pth'.format(mlp_type, n_steps))\n",
    "\n",
    "    plt.plot(np.array(elbo_ests))\n",
    "    plt.title('ELBO Plot')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('ELBO')\n",
    "    plt.savefig('figs/elbo_plot_mnist_{0}_{1}.png'.format(mlp_type, n_steps))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc532w",
   "language": "python",
   "name": "cpsc532w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e76487-4c02-4ba0-910b-16c6d0b11d56",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notes\n",
    "\n",
    "The equivariant neural network implementation is loosely based on [PointNet](https://arxiv.org/pdf/1612.00593.pdf). I only implemented the first 'standard transform layer', but could design a much more detailed one. Here is the [GitHub repo](https://github.com/fxia22/pointnet.pytorch/blob/f0c2430b0b1529e3f76fb5d6cd6ca14be763d975/pointnet/model.py#L11) to the code\n",
    "\n",
    "## Hyperparameters\n",
    "- Adam{\"lr\": 0.00001} / SELU() / max / SVI\n",
    "\n",
    "## BUGS\n",
    "- cluster degeneracy (one cluster makes up the majority of the proportion vector)\n",
    "    - [DEEP UNSUPERVISED CLUSTERING WITH GAUSSIAN MIXTURE VARIATIONAL AUTOENCODERS](https://arxiv.org/pdf/1611.02648.pdf)\n",
    "\n",
    "\n",
    "## Resources\n",
    "- [Tutorial on to_event and .expand()](https://bochang.me/blog/posts/pytorch-distributions/)\n",
    "- [Event, Batch, Sample shapes](https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/)\n",
    "- [Debugging Neural Networks](https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba80362-5a0d-4e68-909c-1b8e068b4ea5",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa519fae-037a-4151-a476-b367569a8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointnet import PointNet\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import *\n",
    "from pyro.infer import Predictive, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, AdamW\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ca45f-c7cd-40e4-896f-7a1702c3ff57",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8c112-8db7-4a81-a0b7-6830ff06eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500  # number of data points\n",
    "M = 2  # number of features\n",
    "T = 5  # Fixed number of components.\n",
    "\n",
    "cov = np.identity(M)  # covariance matrix is just the identity for now\n",
    "\n",
    "# generate data\n",
    "clust1 = np.random.multivariate_normal(np.zeros(M), cov, 100)\n",
    "clust2 = np.random.multivariate_normal(np.ones(M)*10, cov, 100)\n",
    "clust3 = np.random.multivariate_normal(np.ones(M)*-10, cov, 100)\n",
    "clust4 = np.random.multivariate_normal([10, -10], cov, 100)\n",
    "clust5 = np.random.multivariate_normal([-10, 10], cov, 100)\n",
    "data = np.concatenate((clust1, clust2, clust3, clust4, clust5))\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.grid()\n",
    "\n",
    "data = torch.from_numpy(data).float()  # convert numpy to torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59375c56-e15d-41bb-b47f-605a1dceeef2",
   "metadata": {},
   "source": [
    "### Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664360d8-2a33-4f51-b025-a75dc061de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, step):\n",
    "    # global variables\n",
    "    alpha = torch.ones(T)\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))\n",
    "    \n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(torch.zeros(M), torch.eye(M)))\n",
    "\n",
    "    # local variables\n",
    "    with pyro.plate('data', N):\n",
    "        assignment = pyro.sample('assignments', Categorical(weights))\n",
    "        pyro.sample('obs', MultivariateNormal(locs[assignment], torch.eye(M)), obs=data)\n",
    "        \n",
    "def guide(data, step):\n",
    "    # amortize using MLP\n",
    "    pyro.module('alpha_mlp', alpha_mlp)\n",
    "    pyro.module('tau_mlp', tau_mlp)\n",
    "    \n",
    "    # sample mixture components mu\n",
    "    tau = tau_mlp(data.permute(1,0).float())\n",
    "    tau = tau.view(5,2)  # reshape tensor\n",
    "    \n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(tau, torch.eye(M)))\n",
    "    \n",
    "    # sample cluster assignments\n",
    "    alpha = alpha_mlp(data.permute(1,0).float()) # returns a vector of length T\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))  # vector of length T\n",
    "    with pyro.plate('data', N):\n",
    "        assignments = pyro.sample('assignments', Categorical(weights))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        \n",
    "        print('='*10, 'Iteration {}'.format(step), '='*10)\n",
    "        weight_data = [weights[i] for i in range(len(weights))]\n",
    "        weight_data.insert(0, 'props')\n",
    "\n",
    "        mu1_data = [locs[i,0] for i in range(locs.shape[0])]\n",
    "        mu1_data.insert(0, 'mu1')\n",
    "\n",
    "        mu2_data = [locs[i,1] for i in range(locs.shape[0])]\n",
    "        mu2_data.insert(0, 'mu2')\n",
    "        \n",
    "        data = [weight_data, mu1_data, mu2_data]\n",
    "        \n",
    "        print(tabulate(data, headers=['', 'clust1', 'clust2', 'clust3', 'clust4', 'clust5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a1f45-34dd-475c-9284-e8f9f7d13acf",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c1dff-32e4-4497-b61b-fcd8662b9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry = True\n",
    "\n",
    "alpha_mlp = PointNet(T, M).float() \n",
    "tau_mlp = PointNet(T*M, M).float()\n",
    "\n",
    "adam_params = {\"lr\": 0.00001}\n",
    "optimizer = Adam(adam_params)\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8b289-b3d3-4453-9aea-1c4b4c0fbed6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90473e97-55ef-4fb3-92f7-c114746095d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50000\n",
    "start = time.time()\n",
    "for step in range(n_steps):\n",
    "    svi.step(data, step)\n",
    "    pyro.get_param_store()\n",
    "    if step % 100 == 0:\n",
    "        end = time.time()\n",
    "        print('took', end-start, 'seconds')\n",
    "        start = time.time()\n",
    "        \n",
    "        if not dry:\n",
    "            torch.save({'model_state_dict': alpha_mlp.state_dict(),\n",
    "                       }, 'saved_models/alpha_mlp_{}.pth'.format(step))\n",
    "\n",
    "            torch.save({'model_state_dict': tau_mlp.state_dict(),\n",
    "                       }, 'saved_models/tau_mlp_{}.pth'.format(step))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc532w",
   "language": "python",
   "name": "cpsc532w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atomic-iraqi",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notes\n",
    "\n",
    "The equivariant neural network implementation is loosely based on [PointNet](https://arxiv.org/pdf/1612.00593.pdf). I only implemented the first 'standard transform layer', but could design a much more detailed one. Here is the [GitHub repo](https://github.com/fxia22/pointnet.pytorch/blob/f0c2430b0b1529e3f76fb5d6cd6ca14be763d975/pointnet/model.py#L11) to the code\n",
    "\n",
    "## Hyperparameters\n",
    "- Adam{\"lr\": 0.00001} / SELU() / max / SVI\n",
    "\n",
    "## Comparison\n",
    "- Amortized\n",
    "    - PermNet: 14 sec / iter\n",
    "- Not Amortized\n",
    "    - PermNet: 15 sec / iter\n",
    "\n",
    "## BUGS\n",
    "- cluster degeneracy w/ pointnet (one cluster makes up the majority of the proportion vector)\n",
    "    - [DEEP UNSUPERVISED CLUSTERING WITH GAUSSIAN MIXTURE VARIATIONAL AUTOENCODERS](https://arxiv.org/pdf/1611.02648.pdf)\n",
    "\n",
    "\n",
    "## Resources\n",
    "- [Tutorial on to_event and .expand()](https://bochang.me/blog/posts/pytorch-distributions/)\n",
    "- [Event, Batch, Sample shapes](https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/)\n",
    "- [Debugging Neural Networks](https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-orchestra",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welcome-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointnet import PointNet\n",
    "from permnet import PermNet\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import *\n",
    "from pyro.infer import Predictive, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, AdamW\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-logic",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promising-omaha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 500  # number of data points\n",
    "M = 2  # number of features\n",
    "T = 5  # Fixed number of components.\n",
    "\n",
    "cov = np.identity(M)  # covariance matrix is just the identity for now\n",
    "\n",
    "# generate data\n",
    "clust1 = np.random.multivariate_normal(np.zeros(M), cov, 100)\n",
    "clust2 = np.random.multivariate_normal(np.ones(M)*10, cov, 100)\n",
    "clust3 = np.random.multivariate_normal(np.ones(M)*-10, cov, 100)\n",
    "clust4 = np.random.multivariate_normal([10, -10], cov, 100)\n",
    "clust5 = np.random.multivariate_normal([-10, 10], cov, 100)\n",
    "data = np.concatenate((clust1, clust2, clust3, clust4, clust5))\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.grid()\n",
    "\n",
    "data = torch.from_numpy(data).float()  # convert numpy to torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-board",
   "metadata": {},
   "source": [
    "### Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "russian-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, step):\n",
    "    # global variables\n",
    "    alpha = torch.ones(T)\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))\n",
    "    \n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(torch.zeros(M), torch.eye(M)))\n",
    "\n",
    "    # local variables\n",
    "    with pyro.plate('data', N):\n",
    "        assignment = pyro.sample('assignments', Categorical(weights))\n",
    "        pyro.sample('obs', MultivariateNormal(locs[assignment], torch.eye(M)), obs=data)\n",
    "        \n",
    "def guide(data, step):\n",
    "    \n",
    "    # train nn if doing offline training\n",
    "    if not amortize:\n",
    "        pyro.module('alpha_mlp', alpha_mlp)\n",
    "        pyro.module('tau_mlp', tau_mlp)\n",
    "    \n",
    "    if use_gpu: \n",
    "        data = data.cuda()\n",
    "    \n",
    "    # sample mixture components mu\n",
    "    tau = tau_mlp(data.float())\n",
    "    tau = tau.view(T,M)  # reshape tensor\n",
    "    \n",
    "    with pyro.plate('components', T):\n",
    "        locs = pyro.sample('locs', MultivariateNormal(tau, torch.eye(M)))\n",
    "    \n",
    "    # sample cluster assignments\n",
    "    alpha = alpha_mlp(data.float()) # returns a vector of length T\n",
    "    weights = pyro.sample('weights', Dirichlet(alpha))  # vector of length T\n",
    "    with pyro.plate('data', N):\n",
    "        assignments = pyro.sample('assignments', Categorical(weights))\n",
    "    \n",
    "    if step % log_iter == 0:\n",
    "        \n",
    "        print('='*10, 'Iteration {}'.format(step), '='*10)\n",
    "        weight_data = [weights[0][i] for i in range(len(weights[0]))]\n",
    "        weight_data.insert(0, 'props')\n",
    "\n",
    "        mu1_data = [locs[i,0] for i in range(locs.shape[0])]\n",
    "        mu1_data.insert(0, 'mu1')\n",
    "\n",
    "        mu2_data = [locs[i,1] for i in range(locs.shape[0])]\n",
    "        mu2_data.insert(0, 'mu2')\n",
    "        \n",
    "        data = [weight_data, mu1_data, mu2_data]\n",
    "        \n",
    "        print(tabulate(data, headers=['', 'clust1', 'clust2', 'clust3', 'clust4', 'clust5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-notion",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using GPU!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyang/.local/lib/python3.7/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "mlp_type = 'permnet'\n",
    "amortize = False\n",
    "\n",
    "\n",
    "if mlp_type == 'pointnet':\n",
    "    alpha_mlp = PointNet(in_ch=M, output_size=T).float() \n",
    "    tau_mlp = PointNet(in_ch=M, output_size=T*M, softmax=False).float()\n",
    "if mlp_type == 'permnet':\n",
    "    alpha_mlp = PermNet(in_ch=M, hidden=256, output_size=T).float()\n",
    "    tau_mlp = PermNet(in_ch=M, hidden=256, output_size=T*M).float()\n",
    "\n",
    "if amortize:\n",
    "    saved_alpha_mlp = torch.load('saved_models/{}/vanilla_alpha_mlp.pth'.format(mlp_type))\n",
    "    saved_tau_mlp = torch.load('saved_models/{}/vanilla_tau_mlp.pth'.format(mlp_type))\n",
    "    \n",
    "    alpha_mlp.load_state_dict(saved_alpha_mlp['model_state_dict'])\n",
    "    tau_mlp.load_state_dict(saved_tau_mlp['model_state_dict'])\n",
    "    \n",
    "\n",
    "adam_params = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_params)\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# use gpu\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('using GPU!')\n",
    "    alpha_mlp = alpha_mlp.cuda()\n",
    "    tau_mlp = tau_mlp.cuda()\n",
    "else:\n",
    "    print('not using GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-bottle",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "major-spirituality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Iteration 0 ==========\n",
      "       clust1                                                                         clust2     clust3     clust4    clust5\n",
      "-----  ---------------------------------------------------------------------------  --------  ---------  ---------  --------\n",
      "props  tensor([0.2970, 0.2482, 0.1224, 0.2969, 0.0354], grad_fn=<SelectBackward0>)\n",
      "mu1    0.6024090051651001                                                            1.85148  -0.449978   3.62224    2.61491\n",
      "mu2    3.220020055770874                                                             2.32618   1.94311   -0.471283   1.68917\n",
      "took 13.208665132522583 seconds\n",
      "========== Iteration 50 ==========\n",
      "       clust1                                                                         clust2     clust3    clust4    clust5\n",
      "-----  ---------------------------------------------------------------------------  --------  ---------  --------  --------\n",
      "props  tensor([0.1630, 0.3130, 0.3555, 0.0799, 0.0887], grad_fn=<SelectBackward0>)\n",
      "mu1    3.205386161804199                                                            -1.54855  -0.374018  -0.18928  0.609721\n",
      "mu2    0.5990817546844482                                                            1.95417   0.590061  -1.19788  0.633428\n",
      "took 694.9851887226105 seconds\n",
      "========== Iteration 100 ==========\n",
      "       clust1                                                                          clust2    clust3    clust4     clust5\n",
      "-----  ---------------------------------------------------------------------------  ---------  --------  --------  ---------\n",
      "props  tensor([0.0815, 0.1444, 0.2423, 0.3299, 0.2019], grad_fn=<SelectBackward0>)\n",
      "mu1    -0.4160574674606323                                                          -0.926318  3.07561   0.143132  -0.188256\n",
      "mu2    1.1169623136520386                                                            2.58596   0.958883  0.53841    0.442827\n",
      "took 696.4784393310547 seconds\n",
      "========== Iteration 150 ==========\n",
      "       clust1                                                                          clust2     clust3     clust4     clust5\n",
      "-----  ---------------------------------------------------------------------------  ---------  ---------  ---------  ---------\n",
      "props  tensor([0.1163, 0.1090, 0.2310, 0.2761, 0.2675], grad_fn=<SelectBackward0>)\n",
      "mu1    -0.9348201751708984                                                          0.668642    0.531583  -0.970338  -0.598586\n",
      "mu2    -0.3740050494670868                                                          0.0899299  -0.381291  -0.407454  -1.13667\n",
      "took 706.3653380870819 seconds\n",
      "========== Iteration 200 ==========\n",
      "       clust1                                                                         clust2     clust3    clust4     clust5\n",
      "-----  ---------------------------------------------------------------------------  --------  ---------  --------  ---------\n",
      "props  tensor([0.0931, 0.1930, 0.0738, 0.2107, 0.4293], grad_fn=<SelectBackward0>)\n",
      "mu1    -0.5648676156997681                                                          -1.50318   0.569021  0.968878  -0.254189\n",
      "mu2    0.8910747170448303                                                           -0.32993  -1.06492   0.663395   1.39065\n",
      "took 706.3511343002319 seconds\n",
      "========== Iteration 250 ==========\n",
      "       clust1                                                                         clust2     clust3     clust4    clust5\n",
      "-----  ---------------------------------------------------------------------------  --------  ---------  ---------  --------\n",
      "props  tensor([0.2261, 0.1380, 0.1377, 0.2263, 0.2719], grad_fn=<SelectBackward0>)\n",
      "mu1    0.8763805031776428                                                           0.384227   1.06926   -0.406001  1.44576\n",
      "mu2    -0.20164799690246582                                                         0.508308  -0.745983  -0.402902  0.202514\n",
      "took 702.0700953006744 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-75e285cd55bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_iter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         params = set(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             ):\n\u001b[1;32m    156\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dry = False\n",
    "log_iter = 50\n",
    "\n",
    "n_steps = 500\n",
    "start = time.time()\n",
    "for step in range(n_steps):\n",
    "    svi.step(data, step)\n",
    "    pyro.get_param_store()\n",
    "    if step % log_iter == 0:\n",
    "        end = time.time()\n",
    "        print('took', end-start, 'seconds')\n",
    "        start = time.time()\n",
    "        \n",
    "    if not dry:\n",
    "        torch.save({'model_state_dict': alpha_mlp.state_dict(),\n",
    "                    'steps': n_steps\n",
    "                   }, 'saved_models/{}/vanilla_alpha_mlp.pth'.format(mlp_type))\n",
    "\n",
    "        torch.save({'model_state_dict': tau_mlp.state_dict(),\n",
    "                    'steps': n_steps\n",
    "                   }, 'saved_models/{}/vanilla_tau_mlp.pth'.format(mlp_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc533y",
   "language": "python",
   "name": "cpsc533y"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
